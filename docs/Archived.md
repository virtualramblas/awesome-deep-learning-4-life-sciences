# List of archived papers/tools
This page contains a list of papers/tools published before 2023 and that have been added to the main readme of this repo in the past.  

# Molecules
* [MolDQN](https://github.com/google-research/google-research/tree/master/mol_dqn) - Optimization of molecules via Deep Reinforcement Learning. [[Paper](https://arxiv.org/pdf/1810.08678v3.pdf)]
* [Pasithea](https://github.com/aspuru-guzik-group/Pasithea) - Deep Molecular Dreaming: Inverse Machine Learning for de-novo molecular design and interpretability with surjective representations. [[Paper](https://arxiv.org/pdf/2012.09712v1.pdf)]
* [fragment-based-dgm](https://github.com/marcopodda/fragment-based-dgm) - A Deep Generative Model for fragment-based molecule generation. [[Paper](https://arxiv.org/pdf/2002.12826v1.pdf)]
* [MAT](https://github.com/ardigen/MAT) - **M**olecule **A**ttention **T**ransformer for molecular prediction tasks. [[Paper](https://arxiv.org/pdf/2002.08264v1.pdf)].
* [GLAMOUR](https://github.com/learningmatter-mit/GLAMOUR) - Chemistry-informed Macromolecule Graph Representation for Similarity Computation, Unsupervised and Supervised Learning. [[Paper](https://iopscience.iop.org/article/10.1088/2632-2153/ac545e)]
* [Transformer-M](https://github.com/lsj2408/Transformer-M) - One Transformer that can understand both 2D & 3D molecular data. [[Paper](https://arxiv.org/abs/2210.01765)]  
* [SynNet](https://github.com/wenhao-gao/SynNet) - An amortized approach to synthetic tree generation using neural networks. This model can serve as both a synthesis planning tool and as a tool for synthesizable molecular design.  [[Paper](https://arxiv.org/abs/2110.06389)]
* [SPIB](https://github.com/tiwarylab/State-Predictive-Information-Bottleneck) - SPIB (**S**tate **P**redictive **I**nformation **B**ottleneck) is a Deep Learning-based framework that learns the reaction coordinates from high dimensional molecular simulation trajectories.  [[Paper](https://aip.scitation.org/doi/abs/10.1063/5.0038198)]  
* [MolT5](https://github.com/blender-nlp/MolT5) - A self-supervised learning framework for pretraining models on a vast amount of unlabeled natural language text and molecule strings. [[Paper](https://arxiv.org/abs/2204.11817)]
* [DIONYSUS](https://github.com/aspuru-guzik-group/dionysus) - An extensive study of the calibration and generalizability of probabilistic Machine Learning models on small chemical datasets. [[Paper](https://arxiv.org/abs/2212.01574)]  
* [NVIDIA-PCQM4Mv2](https://github.com/jfpuget/NVIDIA-PCQM4Mv2) - Heterogenous ensemble of models for Molecular Property Prediction. [[Paper](https://arxiv.org/abs/2211.11035)]
* [JAEGER](https://github.com/Novartis/JAEGER) - JT-VAE Generative Modeling (JAEGER) is a deep generative approach for small-molecule design. It is based on the Junction-Tree Variational Auto-Encoder (JT-VAE) method. [[JT-VAE paper](https://arxiv.org/abs/1802.04364)]
* [MoLFormer](https://github.com/IBM/molformer) - A large-scale chemical language model designed with the intention of learning a model trained on small molecules which are represented as SMILES strings. [[Paper](https://www.nature.com/articles/s42256-022-00580-7)]
* [Mol-CycleGAN](https://github.com/ardigen/mol-cycle-gan) - A generative model for molecular optimization. [[Paper](https://www.researchgate.net/publication/338466527_Mol-CycleGAN_A_generative_model_for_molecular_optimization)]
* [EDM](https://github.com/ehoogeboom/e3_diffusion_for_molecules) - Equivariant Diffusion for Molecule Generation in 3D. [[Paper](https://arxiv.org/abs/2203.17003)]  
